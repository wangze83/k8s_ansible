apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: device-plugin-recover-ds
  namespace: kube-system
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      component: gpushare-device-plugin
      app: gpushare
      name: device-plugin-recover-ds
  template:
    metadata:
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        component: gpushare-device-plugin
        app: gpushare
        name: device-plugin-recover-ds
    spec:
      nodeSelector:
        wz.cloud/vgpu: "false"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: aliyun.accelerator/nvidia_count
                operator: Exists
      # nodeSelector:
      #   gpu-instance: "true"
      hostNetwork: true
      initContainers:
        - name: waiting-for-nvidia-driver-daemonset
          image: harbor.wz.net/x./busybox:latest
          command: ["sleep", "10"]
      containers:
      - name: gpushare
        {{- if .Values.pullImageByVPCNetwork }}
        image: "{{ .Values.images.recover.image | replace "registry." "registry-vpc." }}:{{ .Values.images.recover.tag }}"
        {{- else }}
        image: "{{ .Values.images.recover.image }}:{{ .Values.images.recover.tag }}"
        {{- end }}
        imagePullPolicy: {{ .Values.images.recover.pullPolicy }}
        command: 
          - bash 
          - /dp-evict/dp-recover-on-host.sh
        # Make this pod as Guaranteed pod which will never be recovered because of node's resource consumption.
        securityContext:
          privileged: true
        volumeMounts:
        - name: kube-dir
          mountPath: /etc/kubernetes
      volumes:
      - hostPath:
          path: /etc/kubernetes
          type: Directory
        name: kube-dir
